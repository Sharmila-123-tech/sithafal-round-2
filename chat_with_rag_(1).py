# -*- coding: utf-8 -*-
"""Chat_with_RAG (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WhjP27jcQ1Ohg-3slUFiGwk12JxQbUwo
"""

!pip install PyMuPDF
!pip install faiss-cpu
!pip install sentence-transformers

from google.colab import files

# Upload the PDF file from your local machine to Google Colab
uploaded = files.upload()

# Check the name of the uploaded file
uploaded_filename = list(uploaded.keys())[0]  # Get the name of the uploaded file
print(f"Uploaded file: {uploaded_filename}")

!pip install PyMuPDF

import fitz  # PyMuPDF

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path, page_numbers=None):
    doc = fitz.open(pdf_path)
    text = ""
    # Loop through the pages and extract text
    if page_numbers:
        for page_num in page_numbers:
            page = doc.load_page(page_num)  # Page numbering starts from 0
            text += page.get_text()
    else:
        for page in doc:
            text += page.get_text()
    return text

# Extract text from the entire PDF (for debugging)
full_text = extract_text_from_pdf(uploaded_filename)

# Check the full text from the first part of the document
print("Full text preview:", full_text[:1000])  # Display first 1000 characters of full text

pip install pytesseract Pillow

# Install Tesseract OCR
!apt-get install -y tesseract-ocr

# Install pytesseract (Python bindings for Tesseract)
!pip install pytesseract

import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import io

# Function to convert PDF page to image
def pdf_page_to_image(pdf_path, page_num):
    doc = fitz.open(pdf_path)
    page = doc.load_page(page_num)  # Page numbering starts from 0
    pix = page.get_pixmap()  # Render the page as an image
    img_data = pix.tobytes()  # Convert to image data
    img = Image.open(io.BytesIO(img_data))  # Open as a PIL image
    return img

# Function to extract text from an image using OCR
def extract_text_from_image(image):
    text = pytesseract.image_to_string(image)  # Perform OCR on the image
    return text

# Example: Convert page 2 to image and run OCR
pdf_path = "Tables, Charts, and Graphs with Examples from History, Economics, Education, Psychology, Urban Affairs and Everyday Life - 2017-2018 (1).pdf"  # Replace with your PDF path
image_page_2 = pdf_page_to_image(pdf_path, 1)  # Convert page 2 (index 1) to an image
text_page_2_from_image = extract_text_from_image(image_page_2)  # Extract text using OCR

# Print the OCR-extracted text (first 1000 characters for debugging)
print("Text extracted from Page 2 (OCR):")
print(text_page_2_from_image[:1100])  # Print first 1000 characters for inspection

from sentence_transformers import SentenceTransformer

# Function to chunk text
def chunk_text(text, chunk_size=512):
    words = text.split()
    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]
    return chunks

# Load a pre-trained sentence transformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Function to embed text
def embed_text(chunks):
    embeddings = model.encode(chunks)
    return embeddings

# Example: Extract text from page 2 (already done in previous steps)
text_page_2 = "Your extracted text from page 2 goes here..."  # Replace this with actual text from page 2

# Chunk the extracted text into smaller pieces
chunks_page_2 = chunk_text(text_page_2)

# Embedding the chunks from page 2
embeddings_page_2 = embed_text(chunks_page_2)

# Print the first few embeddings
print("Embeddings from page 2:", embeddings_page_2[:3])  # Display first 3 embeddings

import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# Function to create FAISS index
def create_faiss_index(embeddings):
    # Check if embeddings are empty or not
    if embeddings is None or embeddings.shape[0] == 0:  # If embeddings are empty
        print("No embeddings found. Skipping FAISS index creation.")
        return None

    dimension = embeddings.shape[1]  # Dimension of the embeddings
    index = faiss.IndexFlatL2(dimension)  # L2 distance-based index
    index.add(embeddings)  # Add embeddings to the index
    return index

# Example model for generating embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')

# Text data for page 2 (ensure this is a valid, non-empty list of text chunks)
text_page_2 = ["Your chunk of text here..."]  # Replace with actual chunks of text extracted from the PDF

# Generate embeddings for text
embeddings_page_2 = model.encode(text_page_2)  # Generates the embeddings for the text

# Check the shape of the embeddings (for debugging purposes)
print("Shape of embeddings_page_2:", np.array(embeddings_page_2).shape)

# Create FAISS index if embeddings are valid
if embeddings_page_2 is not None and np.array(embeddings_page_2).shape[0] > 0:
    index_page_2 = create_faiss_index(np.array(embeddings_page_2))
    print("FAISS index created successfully.")
else:
    print("Failed to create FAISS index due to empty embeddings.")

import numpy as np
from sentence_transformers import SentenceTransformer
import faiss

# Initialize the model for generating embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')

# Function to create FAISS index
def create_faiss_index(embeddings):
    if embeddings is None or embeddings.shape[0] == 0:
        print("No embeddings found. Skipping FAISS index creation.")
        return None

    dimension = embeddings.shape[1]  # Dimension of the embeddings
    index = faiss.IndexFlatL2(dimension)  # L2 distance-based index
    index.add(embeddings)  # Add embeddings to the index
    return index

# Function to search the index for similar chunks
def search_query(query, index, top_k=5):
    # Embed the user query
    query_embedding = model.encode([query])  # Convert query to embedding
    # Search the FAISS index for the closest matches
    D, I = index.search(np.array(query_embedding), top_k)  # Get top_k closest neighbors
    return D, I

# Example chunks from page 2 (replace this with your actual chunks)
text_page_2 = ["Chunk 1: Information about unemployment",
               "Chunk 2: Degree types and employment statistics",
               "Chunk 3: Analysis of job market trends"]

# Generate embeddings for the text chunks
embeddings_page_2 = model.encode(text_page_2)

# Create FAISS index for page 2
index_page_2 = create_faiss_index(np.array(embeddings_page_2))

# Example query to search
query = "What is the unemployment information based on degree?"

# Perform search on the index
D, I = search_query(query, index_page_2)

# Print results
print("Distances:", D)  # Distances to the closest matches
print("Indices:", I)  # Indices of the closest matches in the text chunks

import requests
import json

def generate_response_with_gpt4(query, chunks):
    # API URL (provided by you)
    api_url = "https://ai-sabbam20042927ai089309489691.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview"

    # Headers with your API key (make sure to keep this secure)
    headers = {
        'Authorization': 'Bearer 6wKBM7DxIiICBFhPcDi5yQNchPUxeuWrbKmCcl4BjizhmIcnW0XLJQQJ99ALACHYHv6XJ3w3AAAAACOGqXKQ',
        'Content-Type': 'application/json'
    }

    # Prepare the payload (query and context/chunks)
    payload = {
        'messages': [{"role": "user", "content": query}],
        'context': ' '.join(chunks)  # Join the chunks as context
    }

    try:
        # Send the POST request
        response = requests.post(api_url, json=payload, headers=headers)

        # Check the status code and response
        if response.status_code == 200:
            response_data = response.json()
            return response_data.get('choices', [{}])[0].get('message', {}).get('content', 'No response generated.')
        else:
            return f"Error: {response.status_code}, {response.text}"

    except Exception as e:
        return f"Exception occurred: {str(e)}"

# Example usage
query = "What is the unemployment data from page 2?"
chunks = ["Text chunk 1 from page 2", "Text chunk 2 from page 2", "Text chunk 3 from page 2"]
response = generate_response_with_gpt4(query, chunks)
print("Response:", response)

import fitz  # PyMuPDF
import numpy as np
import faiss

# Function to extract text from a PDF
def extract_text_from_pdf(pdf_path, page_numbers=None):
    doc = fitz.open(pdf_path)
    text = ""
    if page_numbers:
        for page_num in page_numbers:
            page = doc.load_page(page_num)  # Page numbering starts from 0
            text += page.get_text()
    else:
        for page in doc:
            text += page.get_text()
    return text

# Example: Extract text from pages 2 and 6 of the PDF
pdf_path = "Tables, Charts, and Graphs with Examples from History, Economics, Education, Psychology, Urban Affairs and Everyday Life - 2017-2018 (1).pdf"
text_page_2 = extract_text_from_pdf(pdf_path, page_numbers=[1])  # Page 2 (index 1)
text_page_6 = extract_text_from_pdf(pdf_path, page_numbers=[5])  # Page 6 (index 5)

# Example: Split the extracted text into chunks
chunks_page_2 = text_page_2.split("\n")  # Split by line, customize as per your requirement
chunks_page_6 = text_page_6.split("\n")  # Split by line, customize as per your requirement

# Example function to compare data between two sets of chunks
def compare_data(chunks_1, chunks_2):
    # Simple comparison: find common lines between two chunks
    common_data = list(set(chunks_1) & set(chunks_2))
    comparison_result = f"Found {len(common_data)} common lines."
    return comparison_result

# Compare data between page 2 and page 6
comparison_result = compare_data(chunks_page_2, chunks_page_6)
print("Comparison Result:", comparison_result)

# Assuming you would proceed with embedding and FAISS for further processing...
# (This part is similar to the previous steps provided)

!pip install pdf2image

!apt-get install -y tesseract-ocr

!apt-get install -y poppler-utils

import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_path
import re  # Regex library for more flexible search
from PIL import Image

# Function to extract text from a PDF using PyMuPDF (for readable PDFs)
def extract_text_from_pdf(pdf_path, page_numbers=None):
    doc = fitz.open(pdf_path)
    text = ""
    if page_numbers:
        for page_num in page_numbers:
            page = doc.load_page(page_num)  # Page numbering starts from 0
            text += page.get_text("text")  # Extract text
    else:
        for page in doc:
            text += page.get_text("text")
    return text

# Function to convert PDF to images and apply OCR using Tesseract
def ocr_from_pdf(pdf_path, page_numbers=None):
    images = convert_from_path(pdf_path, first_page=page_numbers[0]+1, last_page=page_numbers[-1]+1) if page_numbers else convert_from_path(pdf_path)
    text = ""
    for img in images:
        text += pytesseract.image_to_string(img)  # Extract text using OCR
    return text

# Function to extract unemployment information based on degree type from page 2
def extract_unemployment_info(text_page_2, degree_type):
    lines = text_page_2.split("\n")
    degree_info = []

    # Use a more flexible search with regex to find unemployment information
    pattern = r"([A-Za-z\s]+)\s*[\d\.\%]+"  # Pattern to match degree and unemployment rate (simple regex)

    for line in lines:
        if degree_type.lower() in line.lower():
            matches = re.findall(pattern, line)
            if matches:
                degree_info.extend(matches)  # Add matched degree information to the list

    return degree_info

# Function to extract tabular data from page 6
def extract_tabular_data(text_page_6):
    lines = text_page_6.split("\n")
    table_data = []

    # Search for lines that may contain tabular data (e.g., columns separated by whitespace or delimiters)
    for line in lines:
        if len(line.strip()) > 0:
            table_data.append(line)

    return table_data

# Example: Extract text from pages 2 and 6 of the PDF
pdf_path = "Tables, Charts, and Graphs with Examples from History, Economics, Education, Psychology, Urban Affairs and Everyday Life - 2017-2018 (1).pdf"  # Replace with the path to your PDF file

# Try extracting text with PyMuPDF first
text_page_2 = extract_text_from_pdf(pdf_path, page_numbers=[1])  # Page 2 (index 1)
text_page_6 = extract_text_from_pdf(pdf_path, page_numbers=[5])  # Page 6 (index 5)

# If the text extraction fails (i.e., no meaningful content), use OCR
if not text_page_2.strip():  # Check if the text from page 2 is empty
    print("Text extraction from page 2 failed, using OCR...")
    text_page_2 = ocr_from_pdf(pdf_path, page_numbers=[1])  # Apply OCR for page 2

if not text_page_6.strip():  # Check if the text from page 6 is empty
    print("Text extraction from page 6 failed, using OCR...")
    text_page_6 = ocr_from_pdf(pdf_path, page_numbers=[5])  # Apply OCR for page 6

# Print the extracted text from page 2 (for debugging purposes)
print("Text from Page 2 (First 1000 characters):")
print(text_page_2[:1000])  # Print a portion to inspect the format

# Extract unemployment information for a specific degree (e.g., Bachelor's)
degree_type = "Bachelor's"  # Example: Change to the degree type you're interested in
unemployment_info_page_2 = extract_unemployment_info(text_page_2, degree_type)

# Extract tabular data from page 6
tabular_data_page_6 = extract_tabular_data(text_page_6)

# Print the results
print("Unemployment Information for", degree_type, ":")
for info in unemployment_info_page_2:
    print(info)

print("\nTabular Data from Page 6:")
for row in tabular_data_page_6:
    print(row)